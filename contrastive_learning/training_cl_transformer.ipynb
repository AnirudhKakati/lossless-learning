{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dffac96-2bb2-4e56-ab1f-ccbd28c366c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/anra7539/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "import json\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6649e4d9-13df-4e67-b485-51711056dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = []\n",
    "# file_name = []\n",
    "\n",
    "# for file in os.listdir('/projects/anra7539/projects/big_data/transcript_summaries'):\n",
    "#     if file != '.ipynb_checkpoints':\n",
    "#         output_file = '/projects/anra7539/projects/big_data/transcript_summaries/'+file\n",
    "#         file_name.append(file)\n",
    "#         with open(output_file, 'r') as f:\n",
    "#             data.append(pd.DataFrame([json.loads(line) for line in f]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea72bc-23ad-4509-bc09-4ac514f5e716",
   "metadata": {},
   "source": [
    "## Generating paraphrases 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23fb85db-dc68-4741-9ea7-269b605e0fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = transformers.T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "# model = transformers.T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\",\n",
    "#                                                                cache_dir = \"/scratch/alpine/anra7539\").to(\"cuda\")\n",
    "\n",
    "# def paraphrase_text(text, paraphrase_limit = 500):\n",
    "#   input_ids = tokenizer.encode(text, \n",
    "#                                return_tensors=\"pt\", \n",
    "#                                truncation=True,\n",
    "#                               max_length = 1024).to(\"cuda\")\n",
    "#   paraphrase_ids = model.generate(input_ids, \n",
    "#                                   max_length=paraphrase_limit,\n",
    "#                                   num_beams=4,\n",
    "#                                   length_penalty=1.1,\n",
    "#                                   do_sample = True)\n",
    "#   paraphrase = tokenizer.decode(paraphrase_ids[0], skip_special_tokens=True)\n",
    "\n",
    "#   return paraphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37aac1d9-b9b2-4457-9260-3ac4c4da4a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in data:\n",
    "#     paraphrases = []\n",
    "#     for summary in tqdm(df.Summary):\n",
    "#         paraphrases.append(paraphrase_text(f\"Paraphrase this text: {summary}\"))\n",
    "#     df[\"paraphrased_Summary\"] = paraphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8439930f-325a-49ab-8745-dd6611227f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(data)):\n",
    "#     data[i].to_csv(f\"/projects/anra7539/projects/big_data/transcript_summaries_with_paraphrases/{file_name[i].split('.json')[0]}.csv\",\n",
    "#                    index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcdc486-535f-4e44-9053-d6a842e276d6",
   "metadata": {},
   "source": [
    "### Contrastive learning df creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5a4fb1e-92f8-40ac-9a4d-195acea9eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for file in os.listdir('/projects/anra7539/projects/big_data/transcript_summaries_with_paraphrases'):\n",
    "    filename = '/projects/anra7539/projects/big_data/transcript_summaries_with_paraphrases/'+file\n",
    "    data.append(pd.read_csv(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ccb1532-ddfc-4663-b52c-c6334ffac318",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    initial_length = len(data[i])\n",
    "    primary_df = data[i].copy()\n",
    "    \n",
    "    secondary_df = pd.concat([df for j, df in enumerate(data) if j != i], ignore_index=True)\n",
    "\n",
    "    num_label_0 = len(primary_df)*3\n",
    "    sampled_summaries = secondary_df.sample(num_label_0, random_state=2025)['Summary'].tolist()\n",
    "\n",
    "    label_0_df = primary_df.sample(n=num_label_0, random_state=2025, replace = True).copy()\n",
    "    label_0_df['paraphrased_Summary'] = sampled_summaries\n",
    "    label_0_df['label'] = [0] * num_label_0\n",
    "\n",
    "    data[i]['label'] = [1] * len(data[i])\n",
    "\n",
    "    data[i] = pd.concat([data[i], label_0_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9d5aa99-ad9a-40c8-998b-8570da89a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e259661d-e6b4-4b93-a236-db5bb807ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_data = pd.concat(data, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fadcbc9-7cd0-496a-9d96-01d849988b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_data.rename(columns = {'paraphrased_Summary':'Summary2'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00754707-c604-4ce8-a81d-6f852fdc61d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1908\n",
       "1     636\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516ad6a7-65f0-4979-af73-6f44701a5c40",
   "metadata": {},
   "source": [
    "## Contrastive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "334e3051-cce0-4312-88c5-d87004b7efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cl_df = cl_data.copy()\n",
    "train, val = train_test_split(full_cl_df, test_size = 0.25, stratify = full_cl_df.label, random_state = 2024)\n",
    "train.reset_index(drop = True, inplace = True)\n",
    "val.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd38a940-9103-4259-97aa-4b36da7ab564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', \n",
    "                            cache_folder = \"/scratch/alpine/anra7539\").to(\"cuda\")\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, embeddings1, embeddings2, labels):\n",
    "        euclidean_distance = torch.nn.functional.pairwise_distance(embeddings1, embeddings2, keepdim=True)\n",
    "        loss_contrastive = torch.mean((1-labels) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (labels) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss_contrastive\n",
    "\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "train_dataset = [[train.Summary[i], train.Summary2[i], train.label[i]] for i in range(len(train))]\n",
    "val_dataset = [[val.Summary[i], val.Summary2[i], val.label[i]] for i in range(len(val))]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "early_stopping_rounds = 10 \n",
    "best_validation_loss = float('inf')\n",
    "no_improvement_count = 0\n",
    "\n",
    "num_epochs = 100\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "progress_bar = tqdm(range(num_training_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc321a67-5d6a-499d-abcf-d8de52cf5f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 2278/12000 [02:30<08:07, 19.92it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping after 19 epochs with no improvement.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        sentences1, sentences2, labels = batch\n",
    "\n",
    "        embeddings1 = torch.tensor(model.encode(sentences1), requires_grad = True).to(\"cuda\")\n",
    "        embeddings2 = torch.tensor(model.encode(sentences2), requires_grad = True).to(\"cuda\")\n",
    "        labels = labels.to(\"cuda\")\n",
    "\n",
    "        loss = criterion(embeddings1, embeddings2, labels.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for batch in val_dataloader:\n",
    "            sentences1, sentences2, labels = batch\n",
    "\n",
    "            embeddings1 = torch.tensor(model.encode(sentences1), requires_grad = False).to(\"cuda\")\n",
    "            embeddings2 = torch.tensor(model.encode(sentences2), requires_grad = False).to(\"cuda\")\n",
    "            labels = labels.to(\"cuda\")\n",
    "\n",
    "            val_loss+=criterion(embeddings1, embeddings2, labels.float())\n",
    "            \n",
    "        if val_loss < best_validation_loss:\n",
    "            best_validation_loss = val_loss\n",
    "            no_improvement_count = 0\n",
    "            \n",
    "            model.save('/scratch/alpine/anra7539/ml_specific_cl_finetuned/best_model')\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "\n",
    "\n",
    "        if no_improvement_count >= early_stopping_rounds:\n",
    "            print(f'Early stopping after {epoch+1} epochs with no improvement.')\n",
    "            break\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d682027-d5c4-464c-911c-6be30c43dcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/anra7539/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5cb8a7777b40cd8c0dd47759565156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/AnkushRaut216/Contrastive-Finetuned-for-AI-all-MiniLM-L6-V2/commit/dc7293fd65c1d6b651006c71aca5f2bd8f96bbee'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, login\n",
    "\n",
    "login()\n",
    "\n",
    "model.push_to_hub(\"AnkushRaut216/Contrastive-Finetuned-for-AI-all-MiniLM-L6-V2\", exist_ok = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b9e82-e739-4ebc-a4f7-fe4980191582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
